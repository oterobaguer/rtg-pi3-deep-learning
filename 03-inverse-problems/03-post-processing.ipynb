{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "04-post-processing.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv3LRFJuvJd3",
        "colab_type": "text"
      },
      "source": [
        "# Learned post processing\n",
        "\n",
        "In the following exercise we will train a notebook for learning a post processing\n",
        "\n",
        "Given $N$ training pairs $S = \\{(y^\\delta_i, x^\\dagger_i)\\}$ we will train the network by minimizing the loss function \n",
        "\n",
        "$$L_S(\\Theta) = \\sum_{i=1}^N \\Vert \\varphi_\\Theta(A^\\dagger y^\\delta_i) - x_i^\\dagger \\Vert$$\n",
        "\n",
        "\n",
        "\n",
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1kJlg4fvJd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from skimage.transform import radon, iradon\n",
        "\n",
        "n, m = 28, 28\n",
        "\n",
        "###############################################\n",
        "# TODO: Set number of angles\n",
        "angles = ...\n",
        "###############################################\n",
        "\n",
        "detectors = 40\n",
        "\n",
        "theta = np.linspace(0.0, 180.0, angles, endpoint=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Nwux-JthvJd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "def forward(phantom):\n",
        "    sinogram = radon(phantom.squeeze(), theta, circle=False)\n",
        "    sinogram += 0.1 * np.random.normal(size=sinogram.shape)\n",
        "    return sinogram\n",
        "\n",
        "\n",
        "class SinogramData(Dataset):\n",
        "    def __init__(self, dataset, forward):\n",
        "        super(SinogramData, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.sinograms = []\n",
        "        self.fbps = []\n",
        "\n",
        "        for i in range(len(self.dataset)):\n",
        "            x = self.dataset[i][0]\n",
        "            self.sinograms.append(torch.tensor(forward(x), dtype=torch.float32))\n",
        "            self.fbps.append(torch.tensor(iradon(self.sinograms[i], theta, circle=False), dtype=torch.float32))\n",
        "\n",
        "        self.forward = forward\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, _ = self.dataset[idx]\n",
        "        y = self.sinograms[idx]\n",
        "        z = self.fbps[idx]\n",
        "        return x, y, z\n",
        "    \n",
        "# datasets (MNIST)\n",
        "mnist_train = SinogramData(datasets.MNIST('/data', train=True, download=True, transform=transform_train), forward)\n",
        "mnist_test  = SinogramData(datasets.MNIST('/data', train=False, download=True, transform=transform_test), forward)\n",
        "\n",
        "# dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size)\n",
        "\n",
        "\n",
        "def visualize_batch(batch, ncols=8):\n",
        "    nrows = (batch.shape[0] + ncols - 1) // ncols\n",
        "    plt.figure(figsize=(15, 2 * nrows))\n",
        "    for i in range(batch.shape[0]):\n",
        "        plt.subplot(nrows, ncols, i+1)\n",
        "        plt.imshow(batch[i].squeeze())\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "x_batch, y_batch, z_batch = next(iter(train_loader))\n",
        "visualize_batch(x_batch)\n",
        "visualize_batch(y_batch)\n",
        "visualize_batch(z_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxlqjHjWvJeC",
        "colab_type": "text"
      },
      "source": [
        "## Create the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlz694KUvJeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "    \n",
        "###############################################\n",
        "# TODO1: Complete the forward method\n",
        "# TODO2: Increase the expression power of the network by adding more layers\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 1, 3, stride=2, padding=1)\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv2 = nn.Conv2d(1, 1, 3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "        return x\n",
        "###############################################\n",
        "\n",
        "###############################################\n",
        "# TODO: Create an instance of the model\n",
        "model = ...\n",
        "###############################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K3eh9qWvJeH",
        "colab_type": "text"
      },
      "source": [
        "## Set the hyperparameters, the loss function and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP0kXKAHvJeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################\n",
        "# TODO: Choose the learning rate\n",
        "lr = ...\n",
        "###############################################\n",
        "\n",
        "# number of epochs\n",
        "n_epochs = 5\n",
        "\n",
        "###############################################\n",
        "# TODO: Choose the loss function\n",
        "...\n",
        "###############################################\n",
        "\n",
        "\n",
        "###############################################\n",
        "# TODO: Choose the optimizer\n",
        "...\n",
        "###############################################\n",
        "\n",
        "# set device to use\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7pgJreBvJeO",
        "colab_type": "text"
      },
      "source": [
        "## Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aysoqB3RvJeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.measure import compare_psnr\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# iterate over epochs\n",
        "for i in range(n_epochs):\n",
        "  \n",
        "    train_loss = 0.0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "    # iterate over batches\n",
        "    for j, (x, y, z) in enumerate(train_loader):\n",
        "        x, y, z = x.to(device), y.to(device), z.to(device)\n",
        "\n",
        "        ######################################################\n",
        "        # TODO: Compute the output and do the backprop\n",
        "        # 1) zero the gradients\n",
        "        # 2) compute the output of the model\n",
        "        # 3) compute the loss function\n",
        "        # 4) backpropagate\n",
        "        # 5) do a gradient step\n",
        "        ...\n",
        "        ######################################################\n",
        "\n",
        "        train_loss += loss.item() * x.shape[0]\n",
        "        if j % 200 == 0:\n",
        "            print('%d/%d' % (j, len(train_loader)))\n",
        "      \n",
        "    \n",
        "    model.eval()\n",
        "    # iterate on batches\n",
        "    for x, y, z in test_loader:\n",
        "        x, y, z = x.to(device), y.to(device), z.to(device)\n",
        "        \n",
        "        ######################################################\n",
        "        # TODO: Evaluate the performance of the current parameters\n",
        "        # 1) compute the output of the network\n",
        "        # 2) compute the loss function\n",
        "        ...\n",
        "        ######################################################\n",
        "\n",
        "        test_loss += loss.item() * x.shape[0]\n",
        "\n",
        "    train_loss /= len(mnist_train)\n",
        "    test_loss /= len(mnist_test)\n",
        "\n",
        "    print('epoch: %d train-error: %.5f test-error: %.4f' % (i, train_loss, test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEYs9HATvJeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PSNR(imtrue, imother):\n",
        "    return compare_psnr(imtrue, imother, data_range=imtrue.max()-imtrue.min())\n",
        "\n",
        "model.eval()\n",
        "# iterate on batches\n",
        "\n",
        "psnr = 0\n",
        "for x, y, z in test_loader:\n",
        "    x, y, z = x.to(device), y.to(device), z.to(device)\n",
        "    outputs = model(z)\n",
        "    \n",
        "    for j in range(x.shape[0]):\n",
        "        psnr += PSNR(x[j].cpu().numpy(), outputs[j].detach().cpu().numpy())\n",
        "        \n",
        "psnr /= len(mnist_test)\n",
        "print(psnr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V15fcUWDvJea",
        "colab_type": "text"
      },
      "source": [
        "## Show some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3Jr8OiFpvJec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from skimage.transform import iradon\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# first batch of data pairs\n",
        "x, y, z = next(iter(test_loader))\n",
        "\n",
        "########################################################\n",
        "# TODO compute the output of the network\n",
        "...\n",
        "########################################################\n",
        "\n",
        "for i in range(x.shape[0]):\n",
        "    plt.figure(figsize=(15, 4))\n",
        "   \n",
        "    plt.subplot(1,3,1)\n",
        "    \n",
        "    plt.imshow(x[i].squeeze())\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(1,3,2)\n",
        "    \n",
        "    x_rec = iradon(y[i].cpu().numpy(), theta, circle=False)\n",
        "    plt.imshow(x_rec)\n",
        "    psnr1 = PSNR(x[i][0].cpu().numpy(), x_rec)\n",
        "    \n",
        "    plt.title('PSNR: %.2f' % psnr1)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    psnr2 = PSNR(x[i].cpu().numpy(), outputs[i].detach().cpu().numpy())\n",
        "    plt.title('PSNR: %.2f' % psnr2)\n",
        "    \n",
        "    plt.imshow(outputs[i].detach().cpu().numpy().squeeze())\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}