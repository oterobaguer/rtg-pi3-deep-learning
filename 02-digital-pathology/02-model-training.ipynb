{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_model_training[solution] (2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjjqMDy3pFsf",
        "colab_type": "text"
      },
      "source": [
        "### Install dependencies\n",
        "Here we install Openslide:\n",
        "https://openslide.org/\n",
        "\n",
        "This library allows us to load the whole-slide images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3_1dgHhpHqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openslide-tools --assume-yes\n",
        "!apt-get install python-openslide --assume-yes\n",
        "!pip install --upgrade setuptools==45.3\n",
        "!pip install openslide-python==1.1.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhIbN3gupd_U",
        "colab_type": "text"
      },
      "source": [
        "### Helper Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Df9ZZUpgoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import openslide\n",
        "\n",
        "from shapely.geometry import Polygon, MultiPolygon\n",
        "from json import JSONEncoder, loads, dumps\n",
        "\n",
        "\n",
        "class Slide:\n",
        "    \"\"\"Implements common functions to most of the standard slides. It is based\n",
        "    on openslide.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, filename):\n",
        "        self.path = filename\n",
        "        self.slide = openslide.OpenSlide(filename)\n",
        "\n",
        "    @property\n",
        "    def file_name(self):\n",
        "        return os.path.split(self.path)[1]\n",
        "\n",
        "    @property\n",
        "    def size(self):\n",
        "        \"\"\"Returns the size (width, height) in pixels of the maximum\n",
        "        magnification level\n",
        "        \"\"\"\n",
        "        return self.slide.level_dimensions[0]\n",
        "\n",
        "    @property\n",
        "    def level_count(self):\n",
        "        \"\"\"Returns the number of zoom levels\"\"\"\n",
        "        return self.slide.level_count\n",
        "\n",
        "    def get_downsample_factor(self, level):\n",
        "        \"\"\"Returns the downsample factor of a level. For example the \n",
        "        downsample factor of level 0 is always 1, level 1 is usually 2...\n",
        "        \"\"\"\n",
        "        return self.slide.level_downsamples[level]\n",
        "\n",
        "    def get_level_size(self, level):\n",
        "        \"\"\"Returns the size in pixels (width, height) of a specific level of\n",
        "        the slide\n",
        "        \"\"\"\n",
        "        return self.slide.level_dimensions[level]\n",
        "\n",
        "    def get_patch(self, x, y, size, level):\n",
        "        \"\"\"Returns an RBG array of a rectangular region\"\"\"\n",
        "        ds = self.get_downsample_factor(level)\n",
        "        return np.array(self.slide.read_region(location=(int(ds * x), int(ds * y)),\n",
        "                                               size=size,\n",
        "                                               level=level).convert(\n",
        "                                                   mode='RGB'))\n",
        "        \n",
        "        \n",
        "class Patch:\n",
        "    \"\"\"Class representing a rectangular region of a slide\"\"\"\n",
        "\n",
        "    def __init__(self, slide, x, y, width, height, level):\n",
        "        self.x, self.y = x, y\n",
        "        self.width, self.height = width, height\n",
        "        self.level = level\n",
        "        self.slide = slide\n",
        "\n",
        "        level_width, level_height = slide.get_level_size(level)\n",
        "        self._polygon = Polygon.from_bounds(\n",
        "            self.x / level_width, \n",
        "            self.y / level_height, \n",
        "            (self.x + self.width) / level_width, \n",
        "            (self.y + self.width) / level_height)\n",
        "        \n",
        "        rel_width = self.width / level_width\n",
        "        rel_height = self.height / level_height\n",
        "\n",
        "        self._internal_polygon = Polygon.from_bounds(\n",
        "            self.x / level_width + 0.2 * rel_width, \n",
        "            self.y / level_height + 0.2 * rel_height, \n",
        "            (self.x + self.width) / level_width - 0.2 * rel_width, \n",
        "            (self.y + self.height) / level_height - 0.2 * rel_height)\n",
        "\n",
        "    @property\n",
        "    def polygon(self):\n",
        "        return self._polygon\n",
        "\n",
        "    @property\n",
        "    def internal_polygon(self):\n",
        "        return self._internal_polygon\n",
        "\n",
        "    @property\n",
        "    def size(self):\n",
        "        return (self.width, self.height)\n",
        "\n",
        "    def plot(self):\n",
        "        points = np.array(self.polygon.exterior.coords)\n",
        "        plt.plot(points[:,0], points[:,1])\n",
        "\n",
        "    def get_image(self):\n",
        "        ds = self.slide.get_downsample_factor(self.level)\n",
        "        return self.slide.get_patch(int(self.x * ds), int(self.y * ds), self.size, self.level)\n",
        "\n",
        "    def get_intersection(self, annotations):\n",
        "        area = 0.0\n",
        "        pol = Polygon()\n",
        "        for annotation in annotations:\n",
        "            pol = pol.union(annotation.polygon.intersection(self.polygon))\n",
        "        return pol.area / self.polygon.area\n",
        "\n",
        "    def get_internal_intersection(self, annotations):\n",
        "        area = 0.0\n",
        "        pol = Polygon()\n",
        "        for annotation in annotations:\n",
        "            pol = pol.union(annotation.polygon.intersection(self.internal_polygon))\n",
        "        return pol.area / self.internal_polygon.area"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW3IMWGv_gy1",
        "colab_type": "text"
      },
      "source": [
        "### Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnWbXMzn_kCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po09O4ylpqgy",
        "colab_type": "text"
      },
      "source": [
        "### Patches Dataset + Data augmentation\n",
        "a) Try some data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBvosQEOvEy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class PatchesDataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df.copy()\n",
        "        self.transforms = transforms\n",
        "        self.slides = {}\n",
        "\n",
        "    def load_image(self, row):\n",
        "        if row['slide'] not in self.slides:\n",
        "            self.slides[row['slide']] = Slide(row['slide'])\n",
        "        slide = self.slides[row['slide']]\n",
        "        x, y = row['x'], row['y']\n",
        "        width, height  = row['width'], row['height']\n",
        "        level = row['level']\n",
        "        return slide.get_patch(x, y, (width, height), level)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        row = self.df.iloc[item]\n",
        "        image = self.load_image(row)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "    \n",
        "        return image, torch.tensor(data=row['target']).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "\n",
        "def set_targets(df):\n",
        "    df['target'] = (df['internal-tumor'] > 1e-3).astype(int)\n",
        "\n",
        "\n",
        "results_path = \"/content/drive/My Drive/Results\"\n",
        "dataset_path = \"/content/drive/My Drive/Dataset A3\"\n",
        "\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "\n",
        "##################  Change these lines  ####################################\n",
        "# TODO: Try some data augmentation\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize(mean, std)]),\n",
        "    'val': transforms.Compose([transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean, std)])\n",
        "}\n",
        "\n",
        "##################  Finish changing here  ##################################\n",
        "\n",
        "datasets = {}\n",
        "\n",
        "max_samples = 20000\n",
        "\n",
        "for phase in ['train', 'val']:\n",
        "    df = pd.read_csv(os.path.join(dataset_path, f'{phase}.csv'))\n",
        "    set_targets(df)\n",
        "\n",
        "    print('Tumor patches: %d' % len(df[df['target'] == 1]))\n",
        "    print('Normal patches: %d' % len(df[df['target'] == 0]))\n",
        "\n",
        "    normal_df = df[df['target'] == 0]\n",
        "    tumor_df = df[df['target'] == 1]\n",
        "\n",
        "    normal_df = normal_df.sample(min(len(normal_df), max_samples), replace=True)\n",
        "\n",
        "    df = pd.concat([normal_df, tumor_df])\n",
        "\n",
        "    datasets[phase] = PatchesDataset(df, transforms=data_transforms[phase])\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    image, target = datasets['train'][0]\n",
        "    plt.title(target.item())\n",
        "    plt.imshow(np.clip(std * (np.array(image)).transpose(1, 2, 0) + mean, 0, 1))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8ROAroNyAZz",
        "colab_type": "text"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY97FavtyD8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def visualize_batch(images, labels, ncols=8):\n",
        "    nrows = (len(images) + ncols - 1) // ncols\n",
        "    plt.figure(figsize=(15, 2 * nrows))\n",
        "    for i in range(len(images)):\n",
        "        plt.subplot(nrows, ncols, i+1)\n",
        "        plt.title(labels[i])\n",
        "        plt.imshow(np.clip(std * np.array(images[i]).transpose(1, 2, 0) + mean, 0, 1))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "loaders = {}\n",
        "batch_size = 64\n",
        "workers = 8\n",
        "\n",
        "for part in ['train', 'val']:\n",
        "    loaders[part] = DataLoader(\n",
        "        datasets[part], \n",
        "        batch_size=batch_size, \n",
        "        shuffle=True, \n",
        "        num_workers=workers, \n",
        "        drop_last=True)\n",
        "    \n",
        "\n",
        "images, labels = next(iter(loaders['train']))\n",
        "visualize_batch(images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW575UYq2HZX",
        "colab_type": "text"
      },
      "source": [
        "### Create the neural network, set the hyperparameters, the loss function and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtgUwwnL2Og2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################  Change these lines  ####################################\n",
        "# TODO: Create the neural network, set the hyperparameters, the loss function and the optimizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################  Finish changing here  ##################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEQ2jQ_U2TI0",
        "colab_type": "text"
      },
      "source": [
        "## Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TPlff0t2VY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display\n",
        "\n",
        "####### statistics part #########\n",
        "\n",
        "loss_history = {'train': [], 'val': []}\n",
        "acc_history = {'train': [], 'val': []}\n",
        "\n",
        "batch_loss = []\n",
        "batch_acc = []\n",
        "\n",
        "\n",
        "def plot_results(epoch, batch, total_batches):\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    plt.figure(figsize=(15, 4))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.title('Batch loss (epoch: %d, batch: %d/%d)' % (epoch, batch, total_batches))\n",
        "    plt.plot(batch_loss)\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('step')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.title('Batch accuracy')\n",
        "    plt.plot(batch_acc)\n",
        "    plt.xlabel('step')\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.title('loss')\n",
        "    for phase in ['train', 'val']:\n",
        "        plt.plot(loss_history[phase], label=phase)\n",
        "        plt.yscale('log')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.xlabel('epoch')\n",
        "    if len(acc_history['train']) > 0:\n",
        "        plt.title('accuracy ' + ','.join(['%s: %.3f' % (phase, acc_history[phase][-1]) for phase in ['train', 'val']]))\n",
        "    else: \n",
        "        plt.title('accuracy')\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        plt.plot(acc_history[phase], label=phase)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show(block=False)\n",
        "\n",
        "####### end statistics part #########"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dol-pF-lIGaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################  Change these lines  ####################################\n",
        "# TODO: Train the network\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##################  Finish changing here  ##################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHYIavFIIe05",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aldio56gE09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "matrix = np.zeros(shape=(2, 2), dtype=np.int)\n",
        "\n",
        "bad_patches = []\n",
        "bad_labels = []\n",
        "\n",
        "th = 0.5\n",
        "\n",
        "model.eval()\n",
        "with torch.set_grad_enabled(False):\n",
        "    matrix = np.zeros(shape=(2, 2))\n",
        "    # iterate on batches\n",
        "    for samples, targets in loaders['val']:\n",
        "        samples, targets = samples.to(device), targets.to(device)\n",
        "        outputs = model(samples)\n",
        "        pred = outputs.max(dim=1)[1]\n",
        "        \n",
        "        for i in range(targets.shape[0]):\n",
        "            matrix[targets[i]][pred[i]] += 1\n",
        "            bad_patches.append(samples[i].cpu())\n",
        "            bad_labels.append(pred[i].cpu())\n",
        "\n",
        "print(matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE8PDSPCiBVp",
        "colab_type": "text"
      },
      "source": [
        "## Prediction examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zLCJ2bGiD2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_names=['normal', 'tumor']\n",
        "\n",
        "model.eval()\n",
        "with torch.set_grad_enabled(False):\n",
        "    samples, targets = next(iter(loaders['val']))\n",
        "    outputs = model(samples.to(device))\n",
        "    pred = outputs.max(dim=1)[1]\n",
        "    visualize_batch(samples, ['%s/%s' % (label_names[targets[i]], label_names[pred[i]]) for i in range(len(labels))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0z8BQs-iUDA",
        "colab_type": "text"
      },
      "source": [
        "## Probabilities of some samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd2F38MFiXnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.set_grad_enabled(False):\n",
        "\n",
        "    samples, targets = next(iter(loaders['val']))\n",
        "    samples, targets = samples.to(device), targets.to(device)\n",
        "    outputs = model(samples)\n",
        "    \n",
        "    for i in range(min(10, targets.shape[0])):\n",
        "        plt.figure(figsize=(8, 2))\n",
        "        \n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(np.clip(std * np.array(samples[i].cpu()).transpose(1, 2, 0) + mean, 0, 1))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        \n",
        "        p = F.softmax(outputs[i].detach().squeeze()).cpu()\n",
        "        plt.bar(range(len(p)), p)\n",
        "        plt.xticks(range(len(p)), label_names, rotation='vertical')\n",
        "        plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtnpMWpxhX_z",
        "colab_type": "text"
      },
      "source": [
        "## Visualize wrongly classified patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiYnUyK0FSmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_batch(bad_patches[:32], bad_labels[:32])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDx-2uUIhdcc",
        "colab_type": "text"
      },
      "source": [
        "## Generate heatmaps\n",
        "\n",
        "a) In order to make this code work the dataset should also return the index of the patch in the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNXx-V8PN0x3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "def generate_heatmap(slide, patches_dataset):\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False):\n",
        "        level = slide.level_count - 2\n",
        "        heatmap_width, heatmap_height = slide.get_level_size(level)\n",
        "\n",
        "        heatmap = np.zeros((heatmap_height, heatmap_width))\n",
        "\n",
        "        print(heatmap.shape)\n",
        "\n",
        "        loader = DataLoader(patches_dataset, batch_size=64)\n",
        "\n",
        "        for images, labels, idx in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = torch.sigmoid(model(images)[..., 0])\n",
        "\n",
        "            for i in range(len(idx)):\n",
        "                patch = patches_dataset.df.iloc[idx[i].item()]\n",
        "                patch_level = patch['level']\n",
        "                level_width, level_height = slide.get_level_size(patch_level)\n",
        "\n",
        "                x, y = patch['x']/level_width, patch['y']/level_height\n",
        "                patch_width, patch_height  = patch['width']/level_width, patch['height']/level_height\n",
        "                \n",
        "                patch_width = int(patch_width * heatmap_width)\n",
        "                patch_height = int(patch_height * heatmap_height)\n",
        "\n",
        "                x_start = int(x * heatmap_width) + int(0.25 * patch_width)\n",
        "                y_start = int(y * heatmap_height) + int(0.25 * patch_height)\n",
        "                x_end = int(x * heatmap_width) + int(0.75 * patch_width)\n",
        "                y_end = int(y * heatmap_height) + int(0.75 * patch_height)\n",
        "                \n",
        "                heatmap[y_start: y_end + 1, x_start: x_end + 1] = np.maximum(heatmap[y_start: y_end + 1, x_start: x_end + 1], outputs[i].detach().cpu())\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "\n",
        "for part in ['train', 'val', 'test']:\n",
        "    df = pd.read_csv(os.path.join(dataset_path, f'{part}.csv'))\n",
        "    set_targets(df)\n",
        "\n",
        "    slides = df['slide'].unique()\n",
        "\n",
        "    for slide_path in slides:\n",
        "        print(slide_path)\n",
        "        slide = Slide(slide_path) \n",
        "\n",
        "        slide_df = df[(df['slide'] == slide_path) & (df['source'] == 'tissue')]\n",
        "        dataset = PatchesDataset(slide_df, data_transforms[part])\n",
        "\n",
        "        heatmap = generate_heatmap(slide, dataset)\n",
        "\n",
        "        plt.figure(figsize=(30, 20))\n",
        "        plt.imshow(heatmap)\n",
        "        plt.show()\n",
        "\n",
        "        image = np.asarray(255 * heatmap).astype(np.uint8)\n",
        "        heatmap_path = os.path.join(results_path, os.path.split(slide_path)[1].replace('.ndpi', '.png'))\n",
        "        Image.fromarray(image, mode = 'L').save(heatmap_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}