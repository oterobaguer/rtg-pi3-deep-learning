{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "02-pytorch-cifar-10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_13vj6bPwCYk"
      },
      "source": [
        "# Training CNNs on CIFAR10\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1224/0*EL6Fy9lJicWeNY2z)\n",
        "\n",
        "\n",
        "### Q1: Load the CIFAR10 data and visualize the first batch\n",
        "a) Try some data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J-O9gyVxwBQZ",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "  \n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "##################  Change these lines  ####################################\n",
        "# TODO: Try some data augmentation\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "##################  Finish changing here  ##################################\n",
        "\n",
        "\n",
        "# datasets (CIFAR10)\n",
        "datasets = {'train': datasets.CIFAR10('/data', train=True, download=True, transform=transform_train),\n",
        "            'val': datasets.CIFAR10('/data', train=False, download=True, transform=transform_val)}\n",
        "\n",
        "# dataloaders\n",
        "loaders = {}\n",
        "for phase in ['train', 'val']:\n",
        "    loaders[phase] = torch.utils.data.DataLoader(datasets[phase], \n",
        "                                                 batch_size=batch_size, \n",
        "                                                 shuffle=True, \n",
        "                                                 drop_last=True)\n",
        "\n",
        "\n",
        "def visualize_batch(batch, labels, ncols=8):\n",
        "    nrows = (batch.shape[0] + ncols - 1) // ncols\n",
        "    plt.figure(figsize=(15, 2*nrows))\n",
        "    for i in range(batch.shape[0]):\n",
        "        plt.subplot(nrows, ncols, i+1)\n",
        "        plt.imshow(batch[i].permute(1, 2, 0).squeeze(), interpolation='bilinear')\n",
        "        plt.title(labels[i])\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "\n",
        "batch, labels = next(iter(loaders['train']))\n",
        "visualize_batch(batch, [label_names[x] for x in labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vCiHLpyH1RQc"
      },
      "source": [
        "### Q2: Create the network\n",
        "a) Try with different models and make your own architectures \\\\\n",
        "b) Set the hyperparameters, the loss function and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsRt-G3U0_it",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "##################  Change these lines  ####################################\n",
        "# TODO: Define the network architecture\n",
        "\n",
        "\n",
        "model = ...\n",
        "\n",
        "\n",
        "##################  Finish changing here  ##################################\n",
        "\n",
        "\n",
        "# learning rate\n",
        "lr = ...\n",
        "\n",
        "# number of epochs\n",
        "n_epochs = ...\n",
        "\n",
        "# loss function\n",
        "lossf = ...\n",
        "\n",
        "# try other optimizer??\n",
        "optimizer = ...\n",
        "\n",
        "# set device to use\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AUahzEBjj6tz"
      },
      "source": [
        "### Q3: Train the network\n",
        "\n",
        "a) Complete the code to compute the ouput of the network, the loss, to do the backprop and to compute an optimization step\n",
        "\n",
        "![alt text](https://4.bp.blogspot.com/-Cu1mJOh11AU/XAIcUyPK0WI/AAAAAAAANNA/BRlNj0Cbt6EJHNH25D4RhB0e6_sbL1Y8QCLcBGAs/s640/28056576_10213577221682063_7572084637958860851_n.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iwMbWezlKQJ6",
        "colab": {}
      },
      "source": [
        "import IPython.display\n",
        "\n",
        "\n",
        "loss_history = {'train': [], 'val': []}\n",
        "acc_history = {'train': [], 'val': []}\n",
        "\n",
        "batch_loss = []\n",
        "batch_acc = []\n",
        "\n",
        "\n",
        "def plot_results(epoch, batch, total_batches):\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.title('Batch loss (epoch: %d, batch: %d/%d)' % (epoch, batch, total_batches))\n",
        "    plt.plot(batch_loss)\n",
        "    plt.yscale('log')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.title('Batch accuracy')\n",
        "    plt.plot(batch_acc)\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.title('loss')\n",
        "    for phase in ['train', 'val']:\n",
        "        plt.plot(loss_history[phase], label=phase)\n",
        "        plt.yscale('log')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    if len(acc_history['train']) > 0:\n",
        "        plt.title('accuracy ' + ','.join(['%s: %.3f' % (phase, acc_history[phase][-1]) for phase in ['train', 'val']]))\n",
        "    else: \n",
        "        plt.title('accuracy')\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        plt.plot(acc_history[phase], label=phase)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show(block=False)\n",
        "\n",
        "\n",
        "# number of batches in for the train and validation phases\n",
        "num_batches = {'train': len(loaders['train']),\n",
        "               'val': len(loaders['val'])}\n",
        "\n",
        "# iterate on epochs\n",
        "for i in range(n_epochs):\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()  \n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        \n",
        "        model.train()\n",
        "\n",
        "        # iterate on batches\n",
        "        for j, (samples, targets) in enumerate(loaders[phase]):\n",
        "            samples, targets = samples.to(device), targets.to(device)\n",
        "            \n",
        "            ##################  Change these lines  ####################################\n",
        "            # TODO: compute the ouput of the network, the loss, do the backprop and an \n",
        "            # optimization step\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ##################  Finish changing here  ##################################\n",
        "\n",
        "            acc = torch.sum(outputs.max(dim=1)[1] == targets).item() / batch_size\n",
        "            running_loss += loss.item()\n",
        "            running_acc += acc\n",
        "            \n",
        "            if j % 50 == 0 and phase == 'train':\n",
        "                # track batch history\n",
        "                batch_loss.append(loss.item())\n",
        "                batch_acc.append(acc)\n",
        "                plot_results(i, j, num_batches[phase])\n",
        "\n",
        "        running_loss /= num_batches[phase]\n",
        "        running_acc /= num_batches[phase]\n",
        "        loss_history[phase].append(running_loss)\n",
        "        acc_history[phase].append(running_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nzNG9Qx6j4y4"
      },
      "source": [
        "### Prediction examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyQx6jKETeBJ",
        "colab": {}
      },
      "source": [
        "model.cpu()\n",
        "samples, labels = next(iter(loaders['val']))\n",
        "outputs = model(samples)\n",
        "pred = outputs.max(dim=1)[1]\n",
        "visualize_batch(samples, ['%s/%s' % (label_names[labels[i]], label_names[pred[i]]) for i in range(len(labels))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o7NNvtTpkKPl"
      },
      "source": [
        "### Confussion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J-FVqzhUf5bv",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "matrix = np.zeros(shape=(10, 10))\n",
        "# iterate on batches\n",
        "for samples, targets in loaders['val']:\n",
        "  samples, targets = samples.to(device), targets.to(device)\n",
        "  outputs = model(samples)\n",
        "  pred = outputs.max(dim=1)[1]\n",
        "  \n",
        "\n",
        "  for i in range(targets.shape[0]):\n",
        "      matrix[targets[i]][pred[i]] += 1\n",
        "\n",
        "plt.imshow(matrix)\n",
        "\n",
        "plt.xticks(range(10), label_names, rotation='vertical');\n",
        "plt.yticks(range(10), label_names);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nst5793vlHh5"
      },
      "source": [
        "### Probabilities of some samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LvrLrVPxlPao",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "batch, labels = next(iter(loaders['val']))\n",
        "model.cpu()\n",
        "model.eval()\n",
        "\n",
        "for i in range(10):\n",
        "    plt.figure(figsize=(8,2))\n",
        "    test_image = batch[i]\n",
        "    \n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(test_image.permute(1, 2, 0).squeeze(), interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    \n",
        "    # Softmax to make the probabilities to be between 0 and 1\n",
        "    p = F.softmax(model(test_image[None]).detach().squeeze())\n",
        "    \n",
        "    plt.bar(range(len(p)), p)\n",
        "    plt.xticks(range(len(p)), label_names, rotation='vertical')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}